{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIL Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn.functional import softmax\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from datasets import Cell_Sampling_new\n",
    "import backbones.cell as cell_model\n",
    "from Utils import adjust_learning_rate, progress_bar, Logger, mkdir_p,dataset_setting,balance_val_split\n",
    "from Utils import utils\n",
    "from sklearn.metrics import top_k_accuracy_score,f1_score,roc_auc_score\n",
    "\n",
    "# Specify the random selection script ID\n",
    "random_script_id =3\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "'''self-supverised learning features'''\n",
    "\n",
    "data_path = \"./image_masks/\"\n",
    "label_id_path_file = './train_32class_batch_idx.txt'\n",
    "\n",
    "\n",
    "random_train_val = './experiment_setup/batch_separated/random{}.txt'.format(random_script_id)\n",
    "\n",
    "\n",
    "\n",
    "# train_set = Cell_Sampling_new.Cell_Features_sampling(data_path,label_id_path_file,train=True,\n",
    "#                                   transform=transform_test,random_train_val=random_train_val)\n",
    "\n",
    "val_set  = Cell_Sampling_new.Cell_Features_sampling(data_path,label_id_path_file,train=False,\n",
    "                         transform=transform_test,random_train_val=random_train_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    weights = [item[2] for item in batch]\n",
    "\n",
    "    return [data,target,weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0,collate_fn=my_collate)\n",
    "valloader = torch.utils.data.DataLoader(val_set, batch_size=1, shuffle=False, num_workers=0,collate_fn=my_collate)\n",
    "train_class_num = val_set.class_number\n",
    "\n",
    "\n",
    "resume = './experimental_models/batch_separated/random{}/CLANet/last_model.pth'.format(random_script_id)\n",
    "\n",
    "net = cell_model.GatedAttention(train_class_num)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "net = utils.DataParallel_withLoss(net,criterion,device_ids=[0],output_device=0)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "net = net.module\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    if os.path.isfile(resume):\n",
    "\n",
    "        print('==> Resuming from checkpoint..')\n",
    "        # change here\n",
    "        checkpoint = torch.load(resume)\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        \n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "        \n",
    "        \n",
    "net = net.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "#print(net.module)\n",
    "\n",
    "batch_predict_results,class_labels,net_features,attention_weights =[],[],[],[]\n",
    "\n",
    "\n",
    "scores, labels,A_weights = [], [],[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets,_) in enumerate(valloader):\n",
    "        inputs, targets = inputs[0].cuda(), targets[0].cuda()\n",
    "\n",
    "        prob,M,A = net(inputs)\n",
    "    \n",
    "\n",
    "        scores.append(softmax(prob))\n",
    "        labels.append(targets)\n",
    "        A_weights.append(A.cpu().numpy().squeeze())\n",
    "        net_features.append(M)\n",
    "        \n",
    "scores = np.array(torch.cat(scores, dim=0).cpu().numpy())\n",
    "labels = np.array(torch.cat(labels, dim=0).cpu().numpy())\n",
    "net_features = np.array(torch.cat(net_features, dim=0).cpu().numpy())\n",
    "#A_weights = np.array(torch.cat(A_weights, dim=0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_num = train_class_num\n",
    "seq_top1_acc,seq_top3_acc,seq_top5_acc = top_k_accuracy_score(labels,scores,k=1,labels=range(class_num))\\\n",
    "                                        ,top_k_accuracy_score(labels,scores,k=3,labels=range(class_num))\\\n",
    "                                        ,top_k_accuracy_score(labels,scores,k=5,labels=range(class_num))\n",
    "\n",
    "seq_f1 = f1_score(labels,np.argmax(scores,axis=1),average='macro')\n",
    "seq_auc = roc_auc_score(labels,scores,multi_class='ovr')\n",
    "\n",
    "print(seq_top1_acc,seq_f1)\n",
    "\n",
    "batch_token = val_set.batch_token\n",
    "b_scores, b_labels = [],[]\n",
    "for batch_id in np.unique(batch_token):\n",
    "    b_ids = np.where(batch_token == batch_id)[0]\n",
    "\n",
    "    b_score, b_label = np.mean(scores[b_ids],axis=0), np.argmax(np.bincount(labels[b_ids]))\n",
    "    \n",
    "    b_scores.append(b_score)\n",
    "    b_labels.append(b_label)\n",
    "\n",
    "b_top1_acc, b_top3_acc, b_top5_acc = top_k_accuracy_score(b_labels, b_scores, k=1, labels=range(class_num)) \\\n",
    "                                    , top_k_accuracy_score(b_labels, b_scores, k=3, labels=range(class_num)) \\\n",
    "                                    , top_k_accuracy_score(b_labels, b_scores, k=5, labels=range(class_num))\n",
    "\n",
    "b_f1 = f1_score(b_labels, np.argmax(b_scores, axis=1), average='macro')\n",
    "b_auc = roc_auc_score(b_labels, b_scores, multi_class='ovr')\n",
    "\n",
    "print(b_top1_acc,b_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id_path_file = '/projects/img/cellbank/Cell_Batch_Classification/model/classification/train_32class_batch_idx.txt'\n",
    "\n",
    "with open(label_id_path_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.rstrip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Confusion matrix for sequence prediction'''\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "matrix = confusion_matrix(labels, np.argmax(scores,axis=1),labels=np.arange(0,32,1))\n",
    "\n",
    "cm = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    if math.isnan(cm[i]) == False:\n",
    "        print(cm[i])\n",
    "        #print(lines[i],cm[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Confusion matrix for batch prediction'''\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "matrix = confusion_matrix(b_labels, np.argmax(b_scores,axis=1),labels=np.arange(0,32,1))\n",
    "\n",
    "cm = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    if math.isnan(cm[i]) == False:\n",
    "        print(cm[i])\n",
    "        #print(lines[i],cm[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "plot a pretty confusion matrix with seaborn\n",
    "Created on Mon Jun 25 14:17:37 2018\n",
    "@author: Wagner Cipriano - wagnerbhbr - gmail - CEFETMG / MMC\n",
    "REFerences:\n",
    "  https://www.mathworks.com/help/nnet/ref/plotconfusion.html\n",
    "  https://stackoverflow.com/questions/28200786/how-to-plot-scikit-learn-classification-report\n",
    "  https://stackoverflow.com/questions/5821125/how-to-plot-confusion-matrix-with-string-axis-rather-than-integer-in-python\n",
    "  https://www.programcreek.com/python/example/96197/seaborn.heatmap\n",
    "  https://stackoverflow.com/questions/19233771/sklearn-plot-confusion-matrix-with-labels/31720054\n",
    "  http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from matplotlib.collections import QuadMesh\n",
    "\n",
    "\n",
    "def get_new_fig(fn, figsize=[9, 9]):\n",
    "    \"\"\"Init graphics\"\"\"\n",
    "    fig1 = plt.figure(fn, figsize)\n",
    "    ax1 = fig1.gca()  # Get Current Axis\n",
    "    ax1.cla()  # clear existing plot\n",
    "    return fig1, ax1\n",
    "\n",
    "\n",
    "def configcell_text_and_colors(\n",
    "    array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0\n",
    "):\n",
    "    \"\"\"\n",
    "    config cell text and colors\n",
    "    and return text elements to add and to dell\n",
    "    @TODO: use fmt\n",
    "    \"\"\"\n",
    "    text_add = []\n",
    "    text_del = []\n",
    "    cell_val = array_df[lin][col]\n",
    "    tot_all = array_df[-1][-1]\n",
    "    per = (float(cell_val) / tot_all) * 100\n",
    "    curr_column = array_df[:, col]\n",
    "    ccl = len(curr_column)\n",
    "\n",
    "    # last line  and/or last column\n",
    "    if (col == (ccl - 1)) or (lin == (ccl - 1)):\n",
    "        # tots and percents\n",
    "        if cell_val != 0:\n",
    "            if (col == ccl - 1) and (lin == ccl - 1):\n",
    "                tot_rig = 0\n",
    "                for i in range(array_df.shape[0] - 1):\n",
    "                    tot_rig += array_df[i][i]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif col == ccl - 1:\n",
    "                tot_rig = array_df[lin][lin]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif lin == ccl - 1:\n",
    "                tot_rig = array_df[col][col]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            per_err = 100 - per_ok\n",
    "        else:\n",
    "            per_ok = per_err = 0\n",
    "\n",
    "        per_ok_s = [\"%.2f%%\" % (per_ok), \"100%\"][per_ok == 100]\n",
    "\n",
    "        # text to DEL\n",
    "        text_del.append(oText)\n",
    "\n",
    "        # text to ADD\n",
    "        font_prop = fm.FontProperties(weight=\"bold\", size=fz)\n",
    "        text_kwargs = dict(\n",
    "            color=\"w\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            gid=\"sum\",\n",
    "            fontproperties=font_prop,\n",
    "        )\n",
    "        lis_txt = [\"%d\" % (cell_val), per_ok_s, \"%.2f%%\" % (per_err)]\n",
    "        lis_kwa = [text_kwargs]\n",
    "        dic = text_kwargs.copy()\n",
    "        dic[\"color\"] = \"g\"\n",
    "        lis_kwa.append(dic)\n",
    "        dic = text_kwargs.copy()\n",
    "        dic[\"color\"] = \"r\"\n",
    "        lis_kwa.append(dic)\n",
    "        lis_pos = [\n",
    "            (oText._x, oText._y - 0.3),\n",
    "            (oText._x, oText._y),\n",
    "            (oText._x, oText._y + 0.3),\n",
    "        ]\n",
    "        for i in range(len(lis_txt)):\n",
    "            newText = dict(\n",
    "                x=lis_pos[i][0],\n",
    "                y=lis_pos[i][1],\n",
    "                text=lis_txt[i],\n",
    "                kw=lis_kwa[i],\n",
    "            )\n",
    "            text_add.append(newText)\n",
    "\n",
    "        # set background color for sum cells (last line and last column)\n",
    "        carr = [0.27, 0.30, 0.27, 1.0]\n",
    "        if (col == ccl - 1) and (lin == ccl - 1):\n",
    "            carr = [0.17, 0.20, 0.17, 1.0]\n",
    "        facecolors[posi] = carr\n",
    "\n",
    "    else:\n",
    "        if per > 0:\n",
    "            txt = \"%s\\n%.2f%%\" % (cell_val, per)\n",
    "        else:\n",
    "            if show_null_values == 0:\n",
    "                txt = \"\"\n",
    "            elif show_null_values == 1:\n",
    "                txt = \"0\"\n",
    "            else:\n",
    "                txt = \"0\\n0.0%\"\n",
    "        oText.set_text(txt)\n",
    "\n",
    "        # main diagonal\n",
    "        if col == lin:\n",
    "            # set color of the textin the diagonal to white\n",
    "            oText.set_color(\"w\")\n",
    "            # set background color in the diagonal to blue\n",
    "            facecolors[posi] = [0.35, 0.8, 0.55, 1.0]\n",
    "        else:\n",
    "            oText.set_color(\"r\")\n",
    "\n",
    "    return text_add, text_del\n",
    "\n",
    "\n",
    "def insert_totals(df_cm):\n",
    "    \"\"\"insert total column and line (the last ones)\"\"\"\n",
    "    sum_col = []\n",
    "    for c in df_cm.columns:\n",
    "        sum_col.append(df_cm[c].sum())\n",
    "    sum_lin = []\n",
    "    for item_line in df_cm.iterrows():\n",
    "        sum_lin.append(item_line[1].sum())\n",
    "    df_cm[\"sum_lin\"] = sum_lin\n",
    "    sum_col.append(np.sum(sum_lin))\n",
    "    df_cm.loc[\"sum_col\"] = sum_col\n",
    "\n",
    "\n",
    "def pp_matrix(\n",
    "    df_cm,\n",
    "    annot=True,\n",
    "    cmap=\"Oranges\",\n",
    "    fmt=\".2f\",\n",
    "    fz=11,\n",
    "    lw=0.5,\n",
    "    cbar=False,\n",
    "    figsize=[8, 8],\n",
    "    show_null_values=0,\n",
    "    pred_val_axis=\"y\",\n",
    "):\n",
    "    \"\"\"\n",
    "    print conf matrix with default layout (like matlab)\n",
    "    params:\n",
    "      df_cm          dataframe (pandas) without totals\n",
    "      annot          print text in each cell\n",
    "      cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:\n",
    "      fz             fontsize\n",
    "      lw             linewidth\n",
    "      pred_val_axis  where to show the prediction values (x or y axis)\n",
    "                      'col' or 'x': show predicted values in columns (x axis) instead lines\n",
    "                      'lin' or 'y': show predicted values in lines   (y axis)\n",
    "    \"\"\"\n",
    "    if pred_val_axis in (\"col\", \"x\"):\n",
    "        xlbl = \"Predicted\"\n",
    "        ylbl = \"Actual\"\n",
    "    else:\n",
    "        xlbl = \"Actual\"\n",
    "        ylbl = \"Predicted\"\n",
    "        df_cm = df_cm.T\n",
    "\n",
    "    # create \"Total\" column\n",
    "    insert_totals(df_cm)\n",
    "\n",
    "    # this is for print allways in the same window\n",
    "    fig, ax1 = get_new_fig(\"Conf matrix default\", figsize)\n",
    "\n",
    "    ax = sn.heatmap(\n",
    "        df_cm,\n",
    "        annot=annot,\n",
    "        annot_kws={\"size\": fz},\n",
    "        linewidths=lw,\n",
    "        ax=ax1,\n",
    "        cbar=cbar,\n",
    "        cmap=cmap,\n",
    "        linecolor=\"w\",\n",
    "        fmt=fmt,\n",
    "    )\n",
    "\n",
    "    # set ticklabels rotation\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=10)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=25, fontsize=10)\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1line.set_visible(False)\n",
    "        t.tick2line.set_visible(False)\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1line.set_visible(False)\n",
    "        t.tick2line.set_visible(False)\n",
    "\n",
    "    # face colors list\n",
    "    quadmesh = ax.findobj(QuadMesh)[0]\n",
    "    facecolors = quadmesh.get_facecolors()\n",
    "\n",
    "    # iter in text elements\n",
    "    array_df = np.array(df_cm.to_records(index=False).tolist())\n",
    "    text_add = []\n",
    "    text_del = []\n",
    "    posi = -1  # from left to right, bottom to top.\n",
    "    for t in ax.collections[0].axes.texts:  # ax.texts:\n",
    "        pos = np.array(t.get_position()) - [0.5, 0.5]\n",
    "        lin = int(pos[1])\n",
    "        col = int(pos[0])\n",
    "        posi += 1\n",
    "\n",
    "        # set text\n",
    "        txt_res = configcell_text_and_colors(\n",
    "            array_df, lin, col, t, facecolors, posi, fz, fmt, show_null_values\n",
    "        )\n",
    "\n",
    "        text_add.extend(txt_res[0])\n",
    "        text_del.extend(txt_res[1])\n",
    "\n",
    "    # remove the old ones\n",
    "    for item in text_del:\n",
    "        item.remove()\n",
    "    # append the new ones\n",
    "    for item in text_add:\n",
    "        ax.text(item[\"x\"], item[\"y\"], item[\"text\"], **item[\"kw\"])\n",
    "\n",
    "    # titles and legends\n",
    "    \n",
    "    ax.set_xlabel(xlbl)\n",
    "    ax.set_ylabel(ylbl)\n",
    "    plt.tight_layout()  # set layout slim\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pp_matrix_from_data(\n",
    "    y_test,\n",
    "    predictions,\n",
    "    columns=None,\n",
    "    annot=True,\n",
    "    cmap=\"Oranges\",\n",
    "    fmt=\".2f\",\n",
    "    fz=11,\n",
    "    lw=0.5,\n",
    "    cbar=False,\n",
    "    figsize=[8, 8],\n",
    "    show_null_values=0,\n",
    "    pred_val_axis=\"lin\",\n",
    "):\n",
    "    \"\"\"\n",
    "    plot confusion matrix function with y_test (actual values) and predictions (predic),\n",
    "    whitout a confusion matrix yet\n",
    "    \"\"\"\n",
    "    from pandas import DataFrame\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    # data\n",
    "    if not columns:\n",
    "        from string import ascii_uppercase\n",
    "\n",
    "        columns = [\n",
    "            \"class %s\" % (i)\n",
    "            for i in list(ascii_uppercase)[0 : len(np.unique(y_test))]\n",
    "        ]\n",
    "\n",
    "    confm = confusion_matrix(y_test, predictions)\n",
    "    df_cm = DataFrame(confm, index=columns, columns=columns)\n",
    "    pp_matrix(\n",
    "        df_cm,\n",
    "        fz=fz,\n",
    "        cmap=cmap,\n",
    "        figsize=figsize,\n",
    "        show_null_values=show_null_values,\n",
    "        pred_val_axis=pred_val_axis,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pp_matrix_from_data(labels, np.argmax(scores,axis=1),columns=lines,figsize=[25,25])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
